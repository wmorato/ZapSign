# Configura√ß√£o das APIs de IA

## üìã Resumo

O m√≥dulo de IA foi **completamente implementado** e est√° pronto para uso! As integra√ß√µes com Gemini e OpenAI est√£o funcionais.

## ‚úÖ O que foi implementado

### 1. **Gemini AI (Google)**
- ‚úÖ Integra√ß√£o completa com `google-generativeai`
- ‚úÖ Modelo: `gemini-pro`
- ‚úÖ Carregamento do template de prompt
- ‚úÖ Parsing de JSON com fallback
- ‚úÖ Tratamento de erros robusto

### 2. **OpenAI (GPT-4)**
- ‚úÖ Integra√ß√£o completa com `openai` SDK
- ‚úÖ Modelo: `gpt-4-turbo-preview` (pode usar `gpt-3.5-turbo` para economia)
- ‚úÖ JSON mode ativado
- ‚úÖ Temperatura 0.3 (mais determin√≠stico)
- ‚úÖ Tratamento de erros robusto

### 3. **Infraestrutura**
- ‚úÖ Task Celery ass√≠ncrona (`analyze_document_content_task`)
- ‚úÖ Modelo `DocumentAnalysis` para armazenar resultados
- ‚úÖ Template de prompt (`prompt_template.txt`)
- ‚úÖ Integra√ß√£o nas views de Document

## üîß Configura√ß√£o

### Passo 1: Instalar depend√™ncias

```bash
cd backend
pip install -r requirements.txt
```

Isso instalar√°:
- `google-generativeai==0.3.2`
- `openai==1.12.0`

### Passo 2: Configurar API Keys

Adicione as chaves no arquivo `.env`:

```bash
# backend/.env
GEMINI_API_KEY=sua-chave-gemini-aqui
OPENAI_API_KEY=sua-chave-openai-aqui
```

#### Como obter as chaves:

**Gemini (Google):**
1. Acesse: https://makersuite.google.com/app/apikey
2. Crie uma nova API key
3. Copie e cole no `.env`

**OpenAI:**
1. Acesse: https://platform.openai.com/api-keys
2. Crie uma nova secret key
3. Copie e cole no `.env`

### Passo 3: Configurar Celery (para processamento ass√≠ncrono)

O Celery j√° est√° configurado no `docker-compose.yml` com Redis.

Para rodar localmente sem Docker:

```bash
# Terminal 1: Redis
redis-server

# Terminal 2: Celery Worker
celery -A config worker -l info

# Terminal 3: Django
python manage.py runserver
```

## üöÄ Como usar

### Autom√°tico (ao criar documento)

Quando voc√™ cria um documento via API, a an√°lise de IA √© disparada automaticamente:

```python
# POST /api/document/
{
    "name": "Contrato de Servi√ßos",
    "company": 1,
    "url_pdf": "https://example.com/contrato.pdf",
    "signers": [...]
}
```

A task Celery ser√° executada em background e salvar√° os resultados em `DocumentAnalysis`.

### Manual (via c√≥digo)

```python
from app.ai.ai_service import AIProvider
from app.ai.tasks import analyze_document_content_task

# Op√ß√£o 1: S√≠ncrono (para testes)
provider = AIProvider(default_model="gemini")
service = provider.get_service("gemini")  # ou "openai"
result = service.analyze_document("Texto do documento aqui...")

# Op√ß√£o 2: Ass√≠ncrono (produ√ß√£o)
analyze_document_content_task.delay(
    document_id=123,
    document_content="Texto do documento...",
    model_name="gemini"  # ou "openai"
)
```

## üìä Estrutura da Resposta

```json
{
    "summary": "Resumo conciso do documento...",
    "missing_topics": [
        "Cl√°usula de rescis√£o",
        "Garantias",
        "Prazos de entrega"
    ],
    "insights": [
        "Documento focado em aspectos legais",
        "Necessidade de clareza em obriga√ß√µes",
        "Potencial para otimiza√ß√£o de linguagem"
    ]
}
```

## üîç Verificar resultados

### Via API

```bash
GET /api/document/{id}/
```

Resposta incluir√°:
```json
{
    "id": 1,
    "name": "Contrato",
    "ai_analysis": {
        "status": "completed",  // pending, processing, completed, failed
        "summary": "...",
        "missing_topics": [...],
        "insights": [...],
        "model_used": "gemini",
        "created_at": "2024-01-01T10:00:00Z"
    }
}
```

### Via Django Admin

1. Acesse: http://localhost:8000/admin/
2. Navegue para: AI ‚Üí Document Analysis
3. Veja todos os resultados de an√°lise

## ‚öôÔ∏è Configura√ß√µes Avan√ßadas

### Trocar modelo padr√£o

Em `document/views.py` linha 131:

```python
analyze_document_content_task.delay(
    document_id=document.id,
    document_content=document_content,
    model_name="openai",  # Trocar para "openai" se preferir
)
```

### Ajustar temperatura (OpenAI)

Em `ai/ai_service.py` linha 165:

```python
temperature=0.3,  # 0.0 = mais determin√≠stico, 1.0 = mais criativo
```

### Usar GPT-3.5 (mais barato)

Em `ai/ai_service.py` linha 157:

```python
model="gpt-3.5-turbo",  # Trocar de gpt-4-turbo-preview
```

## üß™ Testar

### Teste unit√°rio

```bash
cd backend
pytest app/tests/test_ai.py -v
```

### Teste manual

```python
# python manage.py shell
from app.ai.ai_service import AIProvider

provider = AIProvider()
gemini = provider.get_service("gemini")
result = gemini.analyze_document("Este √© um contrato de presta√ß√£o de servi√ßos...")
print(result)
```

## üìù Logs

Os logs est√£o configurados para mostrar:
- ‚úÖ Inicializa√ß√£o dos services
- ‚úÖ In√≠cio e fim de an√°lises
- ‚ùå Erros de API
- ‚ùå Erros de parsing JSON

Verifique em:
```bash
# Console do Django/Celery
# Ou configure logging em settings.py
```

## üí∞ Custos estimados

### Gemini
- **Gratuito** at√© 60 requisi√ß√µes/minuto
- Modelo: gemini-pro

### OpenAI
- **GPT-4 Turbo**: ~$0.01 por 1K tokens (~750 palavras)
- **GPT-3.5 Turbo**: ~$0.001 por 1K tokens (10x mais barato)

Para um documento de 2000 palavras:
- Gemini: **Gr√°tis**
- GPT-4: ~$0.03
- GPT-3.5: ~$0.003

## ‚úÖ Checklist de Configura√ß√£o

- [ ] Instalar depend√™ncias (`pip install -r requirements.txt`)
- [ ] Obter API key do Gemini
- [ ] Obter API key do OpenAI (opcional)
- [ ] Adicionar keys no `.env`
- [ ] Rodar Redis (ou usar Docker)
- [ ] Rodar Celery worker
- [ ] Testar cria√ß√£o de documento
- [ ] Verificar an√°lise no admin ou via API

## üö® Troubleshooting

### Erro: "google-generativeai n√£o instalado"
```bash
pip install google-generativeai==0.3.2
```

### Erro: "openai n√£o instalado"
```bash
pip install openai==1.12.0
```

### Erro: "API Key n√£o configurada"
Verifique se o `.env` est√° correto e se as vari√°veis est√£o sendo carregadas.

### Task Celery n√£o executa
1. Verifique se Redis est√° rodando: `redis-cli ping`
2. Verifique se Celery worker est√° ativo
3. Veja logs do Celery

### An√°lise fica em "pending"
- Celery worker pode n√£o estar rodando
- Verifique logs do Celery para erros

## üìö Pr√≥ximos passos (opcional)

- [ ] Adicionar mais modelos (Claude, LLaMA, etc.)
- [ ] Implementar cache de an√°lises
- [ ] Dashboard de m√©tricas de IA
- [ ] Compara√ß√£o entre modelos
- [ ] Fine-tuning de prompts

---

**Status**: ‚úÖ **TOTALMENTE FUNCIONAL**

As integra√ß√µes de IA est√£o prontas para uso em produ√ß√£o!
